{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/msc-thesis/blob/main/twi_french_seq_seq_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiBmhONTYbXr"
      },
      "source": [
        "# **Machine Translation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iowPxD95Y6nE"
      },
      "source": [
        "This exercise will demonstrate how to build sequence to sequence models with attention for Twi-French machine translation. This code is based on the tensorflow implementation.The code snippet are adapted from from [[1]](https://www.tensorflow.org/text/tutorials/nmt_with_attention)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzMNK6S-ZK6s"
      },
      "source": [
        "## Install Tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5kz0EVda0eP",
        "outputId": "65b28d59-2202-4de4-b15f-049a28588ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.7)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VESvB4rXcGAL"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHosmTGhY5Xm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import sys\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import tensorflow as tf\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq9yZ-Hbc4Vj"
      },
      "source": [
        "## The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt3y-TB7dGzJ"
      },
      "source": [
        "The dataset for this exercise is taken from the paper ENGLISH-AKUAPEM TWI PARALLEL CORPUS and is available at [[2]](https://zenodo.org/record/4432117#.YxTaVtLP1Nj). The french translations were generated using  the googletrans python package [[3]](https://pypi.org/project/googletrans/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz5uvNaOhz0B"
      },
      "source": [
        "Perform stanadardization, unicode normalisation and add aend and start tokens to each sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6WR49aTT_Zj"
      },
      "outputs": [],
      "source": [
        "def read_dataset(number):\n",
        "\n",
        "    french_data = []\n",
        "    with open('/content/verified.french.txt') as file:\n",
        "\n",
        "        line = file.readline()\n",
        "        cnt = 1\n",
        "        while line:\n",
        "            french_data.append(line.strip())\n",
        "            line = file.readline()\n",
        "            cnt += 1\n",
        "\n",
        "    twi_data = []\n",
        "    with open('/content/verified.twi.txt') as file:\n",
        "\n",
        "        line = file.readline()\n",
        "        cnt = 1\n",
        "        while line:\n",
        "            twi_data.append(line.strip())\n",
        "            line = file.readline()\n",
        "            cnt += 1\n",
        "\n",
        "    return french_data[:number],twi_data[:number]\n",
        "\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def normalize_fr(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s\n",
        "\n",
        "def normalize_twi(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.ƆɔɛƐ!?’]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s\n",
        "\n",
        "def add_start_end_token(text):\n",
        "  # lower text\n",
        "  text = tf.strings.lower(text)\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "raw_data_fr,raw_data_twi = read_dataset(10000)\n",
        "raw_data_fr = [normalize_fr(data) for data in raw_data_fr]\n",
        "raw_data_twi = [normalize_twi(data) for data in raw_data_twi]\n",
        "\n",
        "with open('training_twi.txt', 'w') as f:\n",
        "    for line in raw_data_twi:\n",
        "        f.write(f\"{line}\\n\")\n",
        "\n",
        "with open('training_fr.txt', 'w') as f:\n",
        "    for line in raw_data_fr:\n",
        "        f.write(f\"{line}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnvIjcG7oyGg"
      },
      "outputs": [],
      "source": [
        "# build TF datasets from input sentences in both languages\n",
        "lines_dataset_fr = tf.data.TextLineDataset('/content/training_fr.txt')\n",
        "lines_dataset_tw = tf.data.TextLineDataset('/content/training_twi.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW2Is1gkspis",
        "outputId": "2f4314c1-f266-4a85-a659-83d3a43b00f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10000 samples in training data\n"
          ]
        }
      ],
      "source": [
        "NUM_PAIRS = 0\n",
        "for fr in lines_dataset_fr:\n",
        "  NUM_PAIRS += 1\n",
        "print('There are ' + str(NUM_PAIRS) + ' samples in training data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ui8oq9nsqb_",
        "outputId": "d602ec9f-011f-4a2f-f14f-40fb7046b2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Twi:  Nea onni ho adwempa no de adwumaden na ɛba .\n",
            "Twi:  Na biribiara nni hɛ a metumi ayɔ\n",
            "Twi:  Kwaku hui se John ne Abena kurakura wɛn nsa .\n",
            "Twi:  So wubetumi atena ha akosi nnɛnmienu npaamu aduasa awiaberɔ .\n",
            "Twi:  Wonni mmre\n",
            "Twi:  Na ɛtotɛ nkosua aduonu abien .\n",
            "Twi:  Minni nkrante .\n",
            "Twi:  Dɔ n nti na abofra no suɔ\n",
            "Twi:  Me na mewɔ ha .\n",
            "Twi:  Na wonte ase .\n",
            "Twi:  Kwaku to dwom yiye .\n",
            "Twi:  Anadwo biara ɛfrɛ no .\n",
            "Twi:  Kwaku fii ayaresabea hɔ kɔe .\n",
            "Twi:  So mu denneennen\n",
            "Twi:  Wubetumi adi nkonim wɔ ɔko no nyinaa mu nanso wubetumi ahwere ɔko no .\n",
            "Twi:  Kwaku bɔɔ mmɔden sɛ obegyae ɔko a ɛkɔɔ so wɔ Abena ne John ntam no .\n",
            "Twi:  M adwene ne sɛ mɛte eyi ase akɔ Franse kasa mu .\n",
            "Twi:  Na megyae .\n",
            "Twi:  Obiara ani gyee n akokoduru no ho .\n",
            "Twi:  Na nsɔmmisa no ɔyɔ den .\n"
          ]
        }
      ],
      "source": [
        "# verify Twi file interpreted correctly\n",
        "for twi in lines_dataset_tw.take(20):\n",
        "  print(\"Twi: \", twi.numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqr1wwhxs48T",
        "outputId": "8c543e86-5522-42c1-85f0-ebc9b4495c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French:  Ce qui lui manque en charisme elle le compense par avec travail acharne .\n",
            "French:  il n y avait rien je pourrais faire a ce sujet .\n",
            "French:  Kwaku vit John et Abena se tenir la main .\n",
            "French:  Pouvez vous rester jusqu a h ?\n",
            "French:  Vous n avez pas beaucoup de temps .\n",
            "French:  Elle a achete deux douzaines d ufs .\n",
            "French:  Je n ai pas d epee .\n",
            "French:  Pourquoi cette bebe pleure t il ?\n",
            "French:  J appartiens ici .\n",
            "French:  Vous n a pas pas compris .\n",
            "French:  Kwaku chante plutot bien .\n",
            "French:  Il l appelle tous les soirs .\n",
            "French:  Kwaku est sorti de l hopital .\n",
            "French:  Accrochez vous bien .\n",
            "French:  Vous pouvez gagner toutes les batailles encore perdre la guerre .\n",
            "French:  Kwaku a essaye de briser le combat entre Abena et John .\n",
            "French:  Je pense le faire traduire en francais\n",
            "French:  J arreterai .\n",
            "French:  Tout le monde admirait son courage .\n",
            "French:  c est une question difficile\n"
          ]
        }
      ],
      "source": [
        "# verify Hebrew file interpreted correctly\n",
        "for fr in lines_dataset_fr.take(20):\n",
        "  print(\"French: \", fr.numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PBtVPLDtJ99"
      },
      "outputs": [],
      "source": [
        "# combine languages into single dataset\n",
        "combined = tf.data.Dataset.zip((lines_dataset_fr, lines_dataset_tw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZAKOpv1tx_W",
        "outputId": "f0e88228-9289-4d68-ad37-5c3fed9d4f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French:  Ce qui lui manque en charisme elle le compense par avec travail acharne .\n",
            "Twi:  Nea onni ho adwempa no de adwumaden na ɛba .\n",
            "French:  il n y avait rien je pourrais faire a ce sujet .\n",
            "Twi:  Na biribiara nni hɛ a metumi ayɔ\n",
            "French:  Kwaku vit John et Abena se tenir la main .\n",
            "Twi:  Kwaku hui se John ne Abena kurakura wɛn nsa .\n",
            "French:  Pouvez vous rester jusqu a h ?\n",
            "Twi:  So wubetumi atena ha akosi nnɛnmienu npaamu aduasa awiaberɔ .\n",
            "French:  Vous n avez pas beaucoup de temps .\n",
            "Twi:  Wonni mmre\n",
            "French:  Elle a achete deux douzaines d ufs .\n",
            "Twi:  Na ɛtotɛ nkosua aduonu abien .\n",
            "French:  Je n ai pas d epee .\n",
            "Twi:  Minni nkrante .\n",
            "French:  Pourquoi cette bebe pleure t il ?\n",
            "Twi:  Dɔ n nti na abofra no suɔ\n",
            "French:  J appartiens ici .\n",
            "Twi:  Me na mewɔ ha .\n",
            "French:  Vous n a pas pas compris .\n",
            "Twi:  Na wonte ase .\n",
            "French:  Kwaku chante plutot bien .\n",
            "Twi:  Kwaku to dwom yiye .\n",
            "French:  Il l appelle tous les soirs .\n",
            "Twi:  Anadwo biara ɛfrɛ no .\n",
            "French:  Kwaku est sorti de l hopital .\n",
            "Twi:  Kwaku fii ayaresabea hɔ kɔe .\n",
            "French:  Accrochez vous bien .\n",
            "Twi:  So mu denneennen\n",
            "French:  Vous pouvez gagner toutes les batailles encore perdre la guerre .\n",
            "Twi:  Wubetumi adi nkonim wɔ ɔko no nyinaa mu nanso wubetumi ahwere ɔko no .\n",
            "French:  Kwaku a essaye de briser le combat entre Abena et John .\n",
            "Twi:  Kwaku bɔɔ mmɔden sɛ obegyae ɔko a ɛkɔɔ so wɔ Abena ne John ntam no .\n",
            "French:  Je pense le faire traduire en francais\n",
            "Twi:  M adwene ne sɛ mɛte eyi ase akɔ Franse kasa mu .\n",
            "French:  J arreterai .\n",
            "Twi:  Na megyae .\n",
            "French:  Tout le monde admirait son courage .\n",
            "Twi:  Obiara ani gyee n akokoduru no ho .\n",
            "French:  c est une question difficile\n",
            "Twi:  Na nsɔmmisa no ɔyɔ den .\n"
          ]
        }
      ],
      "source": [
        "# verify combined dataset is correct\n",
        "for fr, tw in combined.take(20):\n",
        "  print(\"French: \", fr.numpy().decode('utf-8'))\n",
        "  print(\"Twi: \", tw.numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZySEcMyuxeS"
      },
      "source": [
        "## Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BbRQUXRt3U2"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = NUM_PAIRS \n",
        "BATCH_SIZE = 64\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "  ds\n",
        "  .cache()\n",
        "  .shuffle(BUFFER_SIZE)\n",
        "  .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCxrWPy7vTEZ",
        "outputId": "b557d7e2-01a8-4dc2-dce4-c725ebd1b74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset = make_batches(combined)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQA-sw7wUCD",
        "outputId": "888e0925-a42d-45c0-c19f-e9b0f52cb04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Si vous n allez pas skier je n irai pas non plus .'\n",
            " b'Mon groupe sanguin est A positif .' b'Avez vous un garage ?'\n",
            " b'Pouvez vous venir me chercher a la gare ?' b'Quand reviendras tu ?'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'S\\xc9\\x9b woanforo mmep\\xc9\\x94n yi a me nso meremfa me ho nhy\\xc9\\x9b mu .'\n",
            " b'Me mogya kuw no y\\xc9\\x9b A posiitve .'\n",
            " b'So wow\\xc9\\x94 \\xc9\\x94dan a w\\xc9\\x94de kar sisi mu ?'\n",
            " b'So wubetumi de me afa me w\\xc9\\x94 keteke gyinabea h\\xc9\\x94 ?'\n",
            " b'Bere b\\xc9\\x9bn na wob\\xc9\\x9bsan aba ?'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_target_batch, example_input_batch in dataset.take(1):\n",
        "  print(example_target_batch[:5])\n",
        "  print()\n",
        "  print(example_input_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e86KIYCwkMW"
      },
      "outputs": [],
      "source": [
        "# add start and end tokens\n",
        "def tf_start_and_end_tokens(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QqdmE0uyFDt",
        "outputId": "28b89e87-8313-4a9e-e5eb-fd7153229142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ɛhe na saa frankaa yi fi ba ?\n",
            "[START] Ɛhe na saa frankaa yi fi ba ? [END]\n"
          ]
        }
      ],
      "source": [
        "# verify if start and end tokens\n",
        "example_text = tf.constant('Ɛhe na saa frankaa yi fi ba ?')\n",
        "print(example_text.numpy().decode())\n",
        "print(tf_start_and_end_tokens(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oajmdm0UFITv"
      },
      "source": [
        "## Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXS7QSTFZdz"
      },
      "source": [
        "This standardization function will be wrapped up in a tf.keras.layers.TextVectorization layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rpmQpXHFT-j"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVUf_-3JF1Ju",
        "outputId": "017369b7-5cd9-4155-f188-aacd6ef4c943"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'no', 'sɛ', 'a', 'na', 'so']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Process twi as input\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_start_and_end_tokens,\n",
        "    max_tokens=max_vocab_size)\n",
        "input_text_processor.adapt(lines_dataset_tw)\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFxUzyAFGh8i",
        "outputId": "819d171d-60fa-4bf9-9ca7-b0a070b171c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'a', 'de', 'je', 'est', 'asamoah']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Process french as output\n",
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_start_and_end_tokens,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(lines_dataset_fr)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U3VVe80InAk"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FtuwuAZHZlm",
        "outputId": "d7cc0852-c127-4f2b-dc0d-a133fcd4d96e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[   2,    6, 3390, 4086,   25,    7,   11,  131, 1214,   11],\n",
              "       [   2,   11,  621,  351,    5,   18,    7, 3653,    4,    3],\n",
              "       [   2,    9,  155,  286,    7,   76,   65,  955,   15,   13]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvOlTahyJakK"
      },
      "source": [
        "The get_vocabulary method can be used to convert token IDs back to text:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IjyocNAbJIJy",
        "outputId": "036cebe1-1f15-48a1-c3f2-ecd23159ed15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] sɛ woanforo mmepɔn yi a me nso meremfa me ho nhyɛ mu . [END]   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1L4JnexLLPR"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "IqYmGYMsLL0s",
        "outputId": "95e3fe34-31b2-4ea3-a0d6-4986e9bc8057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX8nNOhVLTIs"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VpENMJ4L3rv"
      },
      "source": [
        "## The Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di-H5ePYLwBw"
      },
      "outputs": [],
      "source": [
        "# Creating the Encoder RNN\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    # shape_checker = ShapeChecker()\n",
        "    # shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    #shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    # shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    # shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnxVZsuBRDaa",
        "outputId": "c9431e7e-c2c7-4939-9511-31429909550f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (64,)\n",
            "Input batch tokens, shape (batch, s): (64, 18)\n",
            "Encoder output, shape (batch, s, units): (64, 18, 1024)\n",
            "Encoder state, shape (batch, units): (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90MC-kwiRnri"
      },
      "source": [
        "## The attention head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stog9zP8Sf1B"
      },
      "source": [
        "This tutorial uses Bahdanau's additive attention [[3]](https://arxiv.org/pdf/1409.0473.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5_qeRKnReHp"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    # shape_checker = ShapeChecker()\n",
        "    # shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    # shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    # shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    #shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    #shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    # shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    # shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTrrd7F3TNkF"
      },
      "outputs": [],
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0vpLscGTZsY",
        "outputId": "b60b7c3c-bfce-448b-ee75-00fcf3ffae44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "(example_tokens != 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BhUWPqYTmTh",
        "outputId": "1f96085a-6daf-4719-c6bc-7965ed82f2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 18)\n"
          ]
        }
      ],
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4jZw5DT5CC"
      },
      "source": [
        "The attention weights should sum to 1.0 for each sequence.\n",
        "\n",
        "Here are the attention weights across the sequences at t=0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0kVlIdTopS",
        "outputId": "0b6e0ee4-e694-478f-ab7c-9e17b63a59c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4z0vW4cUuMq"
      },
      "outputs": [],
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOEbgxeT_5V",
        "outputId": "e0bc8749-4782-440f-b790-9a29fdd5ed2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 2, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "attention_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkqQ3TLfUN1Z",
        "outputId": "7c87dfaa-4471-4377-8637-3c1f16a42999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb97e30ce50>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.suptitle('Attention weights for one sequence')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "a1 = plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "# freeze the xlim\n",
        "plt.xlim(plt.xlim())\n",
        "plt.xlabel('Attention weights')\n",
        "\n",
        "a2 = plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlabel('Attention weights, zoomed')\n",
        "\n",
        "# zoom in\n",
        "top = max(a1.get_ylim())\n",
        "zoom = 0.85*top\n",
        "a2.set_ylim([0.90*top, top])\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbWnoOzEU3MT"
      },
      "source": [
        "## The Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbyHUAj6U7WQ"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSnSww0IVjGh"
      },
      "outputs": [],
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYI8FMFXZf-d"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  # shape_checker = ShapeChecker()\n",
        "  # shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  # shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  # shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  # if state is not None:\n",
        "  #   shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  #shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  # shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  # shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  # shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  # shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  #shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  #shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTXyNYisZoFO"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLzLKIeSXO7z"
      },
      "outputs": [],
      "source": [
        "# VERIFY DECODER\n",
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDB6Q-eGYQDC"
      },
      "outputs": [],
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn4GA2ewYdFf",
        "outputId": "5b361d29-3f79-49bd-c12f-329fffcac536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 5000)\n",
            "state shape: (batch_size, dec_units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRRN-ruJbKz9"
      },
      "outputs": [],
      "source": [
        "# Sample a token according to the logits:\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0kkz-B7bb8B",
        "outputId": "4104437e-1e7d-4589-e3ac-118524d674a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['nation'],\n",
              "       ['verifier'],\n",
              "       ['ponts'],\n",
              "       ['arrivent'],\n",
              "       ['poele']], dtype='<U18')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#Decode the token as the first word of the output:\n",
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VioOXI96b9fo"
      },
      "source": [
        "Now use the decoder to generate a second set of logits.\n",
        "\n",
        "\n",
        "1.   Pass the same enc_output and mask, these haven't changed.\n",
        "2.   Pass the sampled token as new_tokens\n",
        "3.   Pass the decoder_state the decoder returned last time, so the RNN continues with a memory of where it left off last time\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I4I5n_Eb-kW"
      },
      "outputs": [],
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H6V04MecmOj",
        "outputId": "4026eb3f-83fd-49c1-d536-2fce2ef7a3cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['permission'],\n",
              "       ['fragile'],\n",
              "       ['roux'],\n",
              "       ['resta'],\n",
              "       ['rentrez']], dtype='<U18')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaBjysj4dDEs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcvKHLJOcw9V"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # shape_checker = ShapeChecker()\n",
        "    # shape_checker(y_true, ('batch', 't'))\n",
        "    # shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    #shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    #shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fmgvJmRdQB0"
      },
      "outputs": [],
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor,\n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    #self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    #.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E49BBN_VdvhJ"
      },
      "outputs": [],
      "source": [
        "# Implement preprocessing step to:\n",
        "# Receive a batch of input_text, target_text from the tf.data.Dataset.\n",
        "# Convert those raw text inputs to token-embeddings and masks.\n",
        "def _preprocess(self, input_text, target_text):\n",
        "  # self.shape_checker(input_text, ('batch',))\n",
        "  # self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  # self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  # self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  #self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  #self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGRmKo1cfXy0"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdd-CMzjfbaI"
      },
      "outputs": [],
      "source": [
        "# the function The _train_step:\n",
        "#Run the encoder on the input_tokens to get the encoder_output and encoder_state.\n",
        "#Initialize the decoder state and loss.\n",
        "#Loop over the target_tokens:\n",
        "#   Run the decoder one step at a time.\n",
        "#   Calculate the loss for each step.\n",
        "#Accumulate the average loss.\n",
        "#Calculate the gradient of the loss and use the optimizer to apply updates to the model's trainable_variables.\n",
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs\n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    # self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    # self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables\n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qr69EKBgQ6h"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._train_step = _train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX6ZkCh7g7Fg"
      },
      "outputs": [],
      "source": [
        "#The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state).\n",
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  # self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  # self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  # self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO34tTQahMkI"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h79zTlAThWi_"
      },
      "outputs": [],
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUlHXR2AhaJE",
        "outputId": "05419606-d988-4992-e010-9d29650a69f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.517193191416238"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsDXQza2hqP7",
        "outputId": "9858b857-7100-438d-e929-58c3e674ac34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.683935>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6565375>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.60674>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.4657755>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.9364057>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.134259>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.7383065>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.5101314>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.2649755>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.218125>}\n",
            "\n",
            "CPU times: user 1min 32s, sys: 2.6 s, total: 1min 34s\n",
            "Wall time: 58.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3fDBmxOjHyY"
      },
      "source": [
        "While it's easier to debug without a tf.function it does give a performance boost. So now that the _train_step method is working, try the tf.function-wrapped _tf_train_step, to maximize performance while training:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ao9Ksdwih9h"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S6Z_ajojXx8"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpxCtiPFjNxA"
      },
      "outputs": [],
      "source": [
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMULdUPEkFiX",
        "outputId": "c0849cf2-12b1-47b4-e47a-ee923c06c5b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.254215>}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "translator.train_step([example_input_batch, example_target_batch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI2tQMCXkKMx",
        "outputId": "05fb8ed5-b293-4be1-dd23-2042d4e88a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.195173>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0822525>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0159173>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9291272>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8650174>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8629797>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.838396>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.7890248>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.7553785>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6845293>}\n",
            "\n",
            "CPU times: user 1min 28s, sys: 1.74 s, total: 1min 30s\n",
            "Wall time: 49.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwzm9kYkm8Q"
      },
      "source": [
        "A good test of a new model is to see that it can overfit a single batch of input. Try it, the loss should quickly go to zero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "cXq0I7tkkhON",
        "outputId": "19e785da-ded1-49c3-d6d4-95c9cbc18b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb97d8d0310>]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N66xbPpJkubg"
      },
      "outputs": [],
      "source": [
        "# build new copy of translator to train\n",
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fX71r-PlMv1"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb40flt9mBX0",
        "outputId": "50a0c0a0-32f1-4962-b145-2039255140ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "157/157 [==============================] - 783s 5s/step - batch_loss: 1.1632\n",
            "Epoch 2/100\n",
            "116/157 [=====================>........] - ETA: 3:20 - batch_loss: 0.8468"
          ]
        }
      ],
      "source": [
        "train_translator.fit(dataset, epochs=100,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eYpGUEL7mFz6"
      },
      "outputs": [],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fiiWVrHom7Lh"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QMT9Y4j8nDx6"
      },
      "outputs": [],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mChNybeSnnJt"
      },
      "source": [
        "## Convert token IDs to tex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ABlX1N1fnPOE"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  # shape_checker = ShapeChecker()\n",
        "  # shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  # shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  #shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  #shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Twa3joiBn-oJ"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4fHuw9a8oEjH"
      },
      "outputs": [],
      "source": [
        "#Input some random token IDs and see what it generates:\n",
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_X34mZJobL4"
      },
      "source": [
        "Sample from the decoder's predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nU8cEayOoUnw"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  # shape_checker = ShapeChecker()\n",
        "  # # 't' is usually 1 here.\n",
        "  # shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  # shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  #shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "\n",
        "  #shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ChfSjfe-on3-"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G26hc3mEotML"
      },
      "outputs": [],
      "source": [
        "# Test run this function on some random inputs:\n",
        "\n",
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JbA3djpto1Ck"
      },
      "outputs": [],
      "source": [
        "# Implement the translation loop\n",
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wsuZeVSSpX-g"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i7Udh2-vpYqg"
      },
      "outputs": [],
      "source": [
        "# Run it on a simple input:\n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'Yɛn agyanom Nyankopɔn .', # \"Dieu de nos pères.\"\n",
        "    'Eyi ne m’asetra .', # \"C'est ma vie.\"\"\n",
        "])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qi2FCVlaqkV8"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqHmHDmBq_9I"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5RvnlerYrOoF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "19Ul18HRrsCv"
      },
      "outputs": [],
      "source": [
        "a = result['attention'][0]\n",
        "\n",
        "print(np.sum(a, axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qLOSGsqZrsx1"
      },
      "outputs": [],
      "source": [
        "_ = plt.bar(range(len(a[0, :])), a[0, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNkM4SIor2df"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.array(a), vmin=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCi_N-mcr9K0"
      },
      "outputs": [],
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_start_and_end_tokens(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w0mHKLz0sGUO"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "plot_attention(result['attention'][i], input_text[i], result['text'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5xqO8PtsULH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc1zDcqtXc7G946QYLDAKF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}