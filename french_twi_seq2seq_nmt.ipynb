{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/msc-thesis/blob/main/french_twi_seq2seq_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqAsWIXdaHh"
      },
      "source": [
        "This exercise will demonstrate how to build sequence to sequence models with attention for French-Twi machine translation. This code is based on the tensorflow implementation of the paper [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) (Luong et al., 2015).The code snippet are adapted from from [[1]](https://www.tensorflow.org/text/tutorials/nmt_with_attention)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-OJN6ybfEP"
      },
      "source": [
        "# Import Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPsStl-KdJmv",
        "outputId": "301eb2c7-b161-480e-bdf5-e45e000e1b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.48.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.7)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2022.9.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 44.8 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.6.15)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=51438a3dfd529f898f9167e61bef456f2cdc2df5fd333019c28832c146fc0d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2022.9.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\"\n",
        "!pip3 install googletrans==3.1.0a0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YET1BasJdKr9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k6W5V1Jg44R"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nh5Z6XSTfREU"
      },
      "outputs": [],
      "source": [
        "# This code was adapted from https://github.com/GhanaNLP/kasa/blob/master/Kasa/Preprocessing.py\n",
        "# A subclass of the kasafrench for preprocessing data\n",
        "# import required library\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "class Preprocessing:\n",
        "    # dummy initialization method\n",
        "    def __init__(self):\n",
        "        # initialize with some default parameters here later\n",
        "        pass\n",
        "\n",
        "    # read in parallel twi - english dataset\n",
        "    def read_parallel_dataset(self, filepath_1, filepath_2, filepath_3=None):\n",
        "        if filepath_3 != None:\n",
        "            # read first language data\n",
        "            lang_1 = []\n",
        "            with open(filepath_1, encoding='utf-8') as file:\n",
        "                line = file.readline()\n",
        "                cnt = 1\n",
        "                while line:\n",
        "                    lang_1.append(line.strip())\n",
        "                    line = file.readline()\n",
        "                    cnt += 1\n",
        "\n",
        "            # read second language data\n",
        "            lang_2 = []\n",
        "            with open(filepath_2, encoding='utf-8') as file:\n",
        "\n",
        "                # twi=file.read()\n",
        "                line = file.readline()\n",
        "                cnt = 1\n",
        "                while line:\n",
        "                    lang_2.append(line.strip())\n",
        "                    line = file.readline()\n",
        "                    cnt += 1\n",
        "            # Read third Language data\n",
        "            lang_3 = []\n",
        "            with open(filepath_3, encoding='utf-8') as file:\n",
        "                line = file.readline()\n",
        "                cnt = 1\n",
        "                while line:\n",
        "                    lang_3.append(line.strip())\n",
        "                    line = file.readline()\n",
        "                    cnt += 1\n",
        "\n",
        "            return lang_1, lang_2, lang_3\n",
        "            \n",
        "        else:\n",
        "            # read first language data\n",
        "            lang_1 = []\n",
        "            with open(filepath_1, encoding='utf-8') as file:\n",
        "                line = file.readline()\n",
        "                cnt = 1\n",
        "                while line:\n",
        "                    lang_1.append(line.strip())\n",
        "                    line = file.readline()\n",
        "                    cnt += 1\n",
        "\n",
        "            # read second language data\n",
        "            lang_2 = []\n",
        "            with open(filepath_2, encoding='utf-8') as file:\n",
        "\n",
        "                # twi=file.read()\n",
        "                line = file.readline()\n",
        "                cnt = 1\n",
        "                while line:\n",
        "                    lang_2.append(line.strip())\n",
        "                    line = file.readline()\n",
        "                    cnt += 1\n",
        "\n",
        "            return lang_1, lang_2\n",
        "\n",
        "    # Define a helper function to remove string accents\n",
        "\n",
        "    def removeStringAccent(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    # normalize input twi sentence\n",
        "    def normalize_twi(self, s):\n",
        "        s = self.removeStringAccent(s)\n",
        "        s = s.lower()\n",
        "        s = re.sub(r'([!.?])', r' \\1', s)\n",
        "        s = re.sub(r'[^a-zA-Z.ƆɔɛƐ!?’]+', r' ', s)\n",
        "        s = re.sub(r'\\s+', r' ', s)\n",
        "        return s\n",
        "\n",
        "    # normalize input french sentence\n",
        "    def normalize_FrEn(self, s):\n",
        "        s = self.removeStringAccent(s)\n",
        "        s = s.lower()\n",
        "        s = re.sub(r'([!.?])', r' \\1', s)\n",
        "        s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "        s = re.sub(r'\\s+', r' ', s)\n",
        "        return s\n",
        "    \n",
        "    def writeTotxt(self,destination,data):\n",
        "        with open(destination, 'w') as f:\n",
        "            for line in data:\n",
        "                 f.write(f\"{line}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XL_-wwIOhEjY"
      },
      "outputs": [],
      "source": [
        "# import preprocessing class \n",
        "# Create an instance of tft preprocessing class\n",
        "preprocessor = Preprocessing()\n",
        "\n",
        "# Read raw parallel dataset\n",
        "raw_data_twi, raw_data_fr = preprocessor.read_parallel_dataset(\n",
        "    filepath_1='/content/drive/MyDrive/verified_twi.txt',\n",
        "    filepath_2='/content/drive/MyDrive/verified_french.txt'\n",
        ")\n",
        "\n",
        "# Normalize the raw data\n",
        "raw_data_fr = [preprocessor.normalize_FrEn(data) for data in raw_data_fr]\n",
        "raw_data_twi = [preprocessor.normalize_twi(data) for data in raw_data_twi]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Tokenizer"
      ],
      "metadata": {
        "id": "Wk43j3wxrqRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions to help reload tokenizer.\n",
        "# add start and end tokens\n",
        "#This functions was use in building the tokenizer\n",
        "#Need to use custmise class to save tokenizer instead\n",
        "\n",
        "def tf_start_and_end_tokens(text):\n",
        "    # Split accented characters.\n",
        "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "    \n",
        "# function to load tokenizer\n",
        "def loadtokenizer(filepath):\n",
        "    tmp = pickle.load(open(filepath, \"rb\"))\n",
        "    temp = tf.keras.layers.TextVectorization.from_config(tmp['config'])\n",
        "    # You have to call `adapt` with some dummy data (BUG in Keras)\n",
        "    temp.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
        "    temp.set_weights(tmp['weights'])\n",
        "    temp.set_vocabulary(tmp['vocabulary'])\n",
        "    return temp"
      ],
      "metadata": {
        "id": "IgcUbiSASeqg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Twi tokenizer\n",
        "twi_tokenizer = loadtokenizer(\"/content/drive/MyDrive/twi_tokenizer .pkl\")\n",
        "#load french tokenizer\n",
        "french_tokenizer = loadtokenizer(\"/content/drive/MyDrive/french_tokenizer .pkl\")"
      ],
      "metadata": {
        "id": "MFF13DWys_2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify tokenizers\n",
        "# Print few lines of our tokenizers vocabulary and length\n",
        "print(f'French Tokenizer:',french_tokenizer.get_vocabulary()[:10])\n",
        "print(f'French Tokenizer size:',len(french_tokenizer.get_vocabulary()))\n",
        "\n",
        "print()\n",
        "print(f'TWI Tokenizer:',twi_tokenizer.get_vocabulary()[-10:])\n",
        "print(f'TWI Tokenizer size:',len(twi_tokenizer.get_vocabulary()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vQkzK52TG_d",
        "outputId": "888de633-06a7-4c54-fca4-714c0c5e9f69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Tokenizer: ['', '[UNK]', '[START]', '[END]', '.', 'a', 'de', 'je', 'est', 'il']\n",
            "French Tokenizer size: 9553\n",
            "\n",
            "TWI Tokenizer: ['abamu', 'abambu', 'abada', 'abaafo', 'aakwantuo', 'aa', '.r', '.meda', '.ma', '.abena']\n",
            "TWI Tokenizer size: 7551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80o2o2FjZYD"
      },
      "source": [
        "# Create Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qIAtMONkhNcF"
      },
      "outputs": [],
      "source": [
        "# split the dataset into training and test sets\n",
        "# Keep 10% of the data as test set\n",
        "train_twi,test_twi,train_fr,test_fr = train_test_split(raw_data_twi,raw_data_fr, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2aFkzc8sj5vO"
      },
      "outputs": [],
      "source": [
        "# write the preprocess traning and test dataset to a file\n",
        "preprocessor.writeTotxt('train_twi.txt',train_twi)\n",
        "preprocessor.writeTotxt('train_fr.txt',train_fr)\n",
        "preprocessor.writeTotxt('test_twi.txt',test_twi)\n",
        "preprocessor.writeTotxt('test_fr.txt',test_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8H8yu3ykCy9"
      },
      "source": [
        "## Build tf Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr47kMLGlGan"
      },
      "source": [
        "## Create Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_batches(inp, targ, BUFFER_SIZE, BATCH_SIZE):\n",
        "        return tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "-cLpANDXTv1V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(train_fr) \n",
        "BATCH_SIZE = 50\n",
        "trained_dataset = make_batches(train_fr,train_twi,BUFFER_SIZE,BATCH_SIZE)"
      ],
      "metadata": {
        "id": "eISsZoZiPswz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset=make_batches(test_fr,test_twi,BUFFER_SIZE,BATCH_SIZE)"
      ],
      "metadata": {
        "id": "c9qB87oFqW5M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnmDbsDDnW1G",
        "outputId": "fe32a73f-44f6-493d-ebf5-008b8e743987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'arretez la .' b'il n y a plus de nourriture .'\n",
            " b'qu avez vous fait de mon livre ?'\n",
            " b'je suis toujours en train de magasiner .'\n",
            " b'vous ferez la meme erreur si les choses continuent ainsi .'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'gyina h\\xc9\\x94' b'aduan biara nni h\\xc9\\x94 a aka .'\n",
            " b'd\\xc9\\x9bn na wode me nwoma no y\\xc9\\x9be ?' b'meda so ara redi gua .'\n",
            " b's\\xc9\\x9b nne\\xc9\\x9bma k\\xc9\\x94 so saa ara a wob\\xc9\\x9by\\xc9\\x9b mfomso koro no ara .'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# verify input and target\n",
        "for  example_input_batch,example_target_batch in trained_dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_test = []\n",
        "twi_test= []\n",
        "\n",
        "for fr_batches, twi_batches in val_dataset:\n",
        "  for line in fr_batches.numpy():\n",
        "    french_test.append(line.decode(\"utf-8\"))\n",
        "  for line in twi_batches.numpy():\n",
        "    twi_test.append(line.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "JCUCtoN0kT_z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOnz10TWzDeK"
      },
      "source": [
        "# Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iLWhTwqK6Nhj"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                                   embedding_dim)\n",
        "\n",
        "        # The GRU RNN layer processes those vectors sequentially.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                         # Return the sequence and state\n",
        "                                         return_sequences=True,\n",
        "                                         return_state=True,\n",
        "                                         recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, tokens, state=None):\n",
        "        # The embedding layer looks up the embedding for each token.\n",
        "        vectors = self.embedding(tokens)\n",
        "\n",
        "        # The GRU processes the embedding sequence.\n",
        "        #    output shape: (batch, s, enc_units)\n",
        "        #    state shape: (batch, enc_units)\n",
        "        output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "        # 4. Returns the new sequence and its state.\n",
        "        return output, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AcFzlXhDjBn"
      },
      "source": [
        "# Create Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G55yaW0U-w_X"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "        self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "    def call(self, query, value, mask):\n",
        "        w1_query = self.W1(query)\n",
        "        w2_key = self.W2(value)\n",
        "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "        value_mask = mask\n",
        "\n",
        "        context_vector, attention_weights = self.attention(\n",
        "            inputs=[w1_query, value, w2_key],\n",
        "            mask=[query_mask, value_mask],\n",
        "            return_attention_scores=True,\n",
        "        )\n",
        "        return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afqcLYScH3ab"
      },
      "source": [
        "# Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MTQH_4OsEgAa"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # For Step 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                                   embedding_dim)\n",
        "\n",
        "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "        self.gru= tf.keras.layers.GRU(self.dec_units,\n",
        "                                         return_sequences=True,\n",
        "                                         return_state=True,\n",
        "                                         recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # For step 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                        use_bias=False)\n",
        "\n",
        "        # For step 5. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
        "\n",
        "\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "    new_tokens: Any\n",
        "    enc_output: Any\n",
        "    mask: Any\n",
        "\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "    logits: Any\n",
        "    attention_weights: Any\n",
        "\n",
        "\n",
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "\n",
        "    # Step 1. Lookup the embeddings\n",
        "    vectors = self.embedding(inputs.new_tokens)\n",
        "    # Step 2. Process one step with the RNN\n",
        "    rnn_output,state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "    # Step 3. Use the RNN output as the query for the attention over the\n",
        "    # encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "    # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "    #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "    # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "    attention_vector = self.Wc(context_and_rnn_output)\n",
        "    # Step 5. Generate logit predictions:\n",
        "    logits = self.fc(attention_vector)\n",
        "    return DecoderOutput(logits, attention_weights), state\n",
        "    \n",
        "\n",
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl0R2Zg6SkRI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pgyqEVm2Ku8T"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        self.name = 'masked_loss'\n",
        "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction='none')\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "\n",
        "        # Calculate the loss for each item in the batch.\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "\n",
        "        # Mask off the losses on padding.\n",
        "        mask = tf.cast(y_true != 0, tf.float32)\n",
        "        loss *= mask\n",
        "\n",
        "        # Return the total.\n",
        "        return tf.reduce_sum(loss)\n",
        "\n",
        "\n",
        "class TrainTranslator(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, units,\n",
        "                 input_text_processor,\n",
        "                 output_text_processor,\n",
        "                 use_tf_function=True):\n",
        "        super().__init__()\n",
        "        # Build the encoder and decoder\n",
        "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                          embedding_dim, units)\n",
        "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                          embedding_dim, units)\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.input_text_processor = input_text_processor\n",
        "        self.output_text_processor = output_text_processor\n",
        "        self.use_tf_function = use_tf_function\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        # .shape_checker = ShapeChecker()\n",
        "        if self.use_tf_function:\n",
        "            return self._tf_train_step(inputs)\n",
        "        else:\n",
        "            return self._train_step(inputs)\n",
        "\n",
        "    # Implement preprocessing step to:\n",
        "    # Receive a batch of input_text, target_text from the tf.data.Dataset.\n",
        "    # Convert those raw text inputs to token-embeddings and masks.\n",
        "    def _preprocess(self, input_text, target_text):\n",
        "        # Convert the text to token IDs\n",
        "        input_tokens = self.input_text_processor(input_text)\n",
        "        target_tokens = self.output_text_processor(target_text)\n",
        "        # Convert IDs to masks.\n",
        "        input_mask = input_tokens != 0\n",
        "\n",
        "        target_mask = target_tokens != 0\n",
        "        return input_tokens, input_mask, target_tokens, target_mask\n",
        "\n",
        "    # the function The _train_step:\n",
        "    # Run the encoder on the input_tokens to get the encoder_output and encoder_state.\n",
        "    # Initialize the decoder state and loss.\n",
        "    # Loop over the target_tokens:\n",
        "    #   Run the decoder one step at a time.\n",
        "    #   Calculate the loss for each step.\n",
        "    # Accumulate the average loss.\n",
        "    # Calculate the gradient of the loss and use the optimizer to apply updates to the model's trainable_variables.\n",
        "\n",
        "    def _train_step(self, inputs):\n",
        "        input_text, target_text = inputs\n",
        "\n",
        "        (input_tokens, input_mask,\n",
        "         target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "        max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Encode the input\n",
        "            enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "            # Initialize the decoder's state to the encoder's final state.\n",
        "            # This only works if the encoder and decoder have the same number of\n",
        "            # units.\n",
        "            dec_state = enc_state\n",
        "            loss = tf.constant(0.0)\n",
        "\n",
        "            for t in tf.range(max_target_length-1):\n",
        "                # Pass in two tokens from the target sequence:\n",
        "                # 1. The current input to the decoder.\n",
        "                # 2. The target for the decoder's next prediction.\n",
        "                new_tokens = target_tokens[:, t:t+2]\n",
        "                step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                                       enc_output, dec_state)\n",
        "                loss = loss + step_loss\n",
        "\n",
        "            # Average the loss over all non padding tokens.\n",
        "            average_loss = loss / \\\n",
        "                tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "        # Apply an optimization step\n",
        "        variables = self.trainable_variables\n",
        "        gradients = tape.gradient(average_loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {'batch_loss': average_loss}\n",
        "\n",
        "    # The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state).\n",
        "\n",
        "    def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "        input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "        # Run the decoder one step.\n",
        "        decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                                     enc_output=enc_output,\n",
        "                                     mask=input_mask)\n",
        "\n",
        "        dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "        # `self.loss` returns the total for non-padded tokens\n",
        "        y = target_token\n",
        "        y_pred = dec_result.logits\n",
        "        step_loss = self.loss(y, y_pred)\n",
        "\n",
        "        return step_loss, dec_state\n",
        "\n",
        "    @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "    def _tf_train_step(self, inputs):\n",
        "        return self._train_step(inputs)\n",
        "\n",
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BI0V2_YNSpO2"
      },
      "outputs": [],
      "source": [
        "# SET INPUT AND OUTPUT PROCESSOR\n",
        "input_text_processor = french_tokenizer\n",
        "output_text_processor = twi_tokenizer\n",
        "\n",
        "# set Hyerperameters\n",
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "31yGNhKaaSU8"
      },
      "outputs": [],
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")\n",
        "train_translator.use_tf_function = True\n",
        "\n",
        "def loadtokenizer(filepath):\n",
        "    tmp = pickle.load(open(filepath, \"rb\"))\n",
        "    temp = tf.keras.layers.TextVectorization.from_config(tmp['config'])\n",
        "    # You have to call `adapt` with some dummy data (BUG in Keras)\n",
        "    temp.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
        "    temp.set_weights(tmp['weights'])\n",
        "    temp.set_vocabulary(tmp['vocabulary'])\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eRCC98HFb7zG",
        "outputId": "5ad41c32-5083-4062-cf72-3aafc3b78a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "458/458 [==============================] - 153s 302ms/step - batch_loss: 4.6922\n",
            "Epoch 2/20\n",
            "458/458 [==============================] - 130s 283ms/step - batch_loss: 4.0233\n",
            "Epoch 3/20\n",
            "458/458 [==============================] - 130s 284ms/step - batch_loss: 3.4329\n",
            "Epoch 4/20\n",
            "458/458 [==============================] - 130s 284ms/step - batch_loss: 2.9146\n",
            "Epoch 5/20\n",
            "458/458 [==============================] - 130s 285ms/step - batch_loss: 2.4472\n",
            "Epoch 6/20\n",
            "458/458 [==============================] - 130s 285ms/step - batch_loss: 1.9909\n",
            "Epoch 7/20\n",
            "458/458 [==============================] - 128s 279ms/step - batch_loss: 1.5399\n",
            "Epoch 8/20\n",
            "458/458 [==============================] - 129s 282ms/step - batch_loss: 1.1278\n",
            "Epoch 9/20\n",
            "458/458 [==============================] - 128s 281ms/step - batch_loss: 0.7652\n",
            "Epoch 10/20\n",
            "458/458 [==============================] - 128s 279ms/step - batch_loss: 0.4878\n",
            "Epoch 11/20\n",
            "458/458 [==============================] - 128s 281ms/step - batch_loss: 0.2923\n",
            "Epoch 12/20\n",
            "458/458 [==============================] - 126s 275ms/step - batch_loss: 0.1741\n",
            "Epoch 13/20\n",
            "458/458 [==============================] - 126s 276ms/step - batch_loss: 0.1099\n",
            "Epoch 14/20\n",
            "458/458 [==============================] - 125s 273ms/step - batch_loss: 0.0803\n",
            "Epoch 15/20\n",
            "458/458 [==============================] - 126s 275ms/step - batch_loss: 0.0728\n",
            "Epoch 16/20\n",
            "458/458 [==============================] - 127s 278ms/step - batch_loss: 0.1388\n",
            "Epoch 17/20\n",
            "458/458 [==============================] - 128s 280ms/step - batch_loss: 0.2535\n",
            "Epoch 18/20\n",
            "458/458 [==============================] - 127s 278ms/step - batch_loss: 0.1367\n",
            "Epoch 19/20\n",
            "458/458 [==============================] - 128s 279ms/step - batch_loss: 0.0683\n",
            "Epoch 20/20\n",
            "458/458 [==============================] - 126s 276ms/step - batch_loss: 0.0395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc527b35bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train_translator.fit(trained_dataset, epochs=20,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ej3vGAWRb9Pt",
        "outputId": "df34b5da-b848-4ffe-a651-03a038e44242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translator"
      ],
      "metadata": {
        "id": "IXqJ52MDyMNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p4NpHontQwGV"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Translator(tf.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, input_text_processor,\n",
        "                 output_text_processor):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.input_text_processor = input_text_processor\n",
        "        self.output_text_processor = output_text_processor\n",
        "\n",
        "        self.output_token_string_from_index = (\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=output_text_processor.get_vocabulary(),\n",
        "                mask_token='',\n",
        "                invert=True))\n",
        "\n",
        "        # The output should never generate padding, unknown, or start.\n",
        "        index_from_string = tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "        token_mask = np.zeros(\n",
        "            [index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "        token_mask[np.array(token_mask_ids)] = True\n",
        "        self.token_mask = token_mask\n",
        "\n",
        "        self.start_token = index_from_string(tf.constant('[START]'))\n",
        "        self.end_token = index_from_string(tf.constant('[END]'))\n",
        "\n",
        "    def tokens_to_text(self, result_tokens):\n",
        "        result_text_tokens = self.output_token_string_from_index(\n",
        "            result_tokens)\n",
        "        result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                             axis=1, separator=' ')\n",
        "        result_text = tf.strings.strip(result_text)\n",
        "        return result_text\n",
        "\n",
        "    def sample(self, logits, temperature):\n",
        "        token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "        logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "        if temperature == 0.0:\n",
        "            new_tokens = tf.argmax(logits, axis=-1)\n",
        "        else:\n",
        "            logits = tf.squeeze(logits, axis=1)\n",
        "            new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                               num_samples=1)\n",
        "\n",
        "        return new_tokens\n",
        "\n",
        "    def translate(self,\n",
        "                  input_text, *,\n",
        "                  max_length=50,\n",
        "                  return_attention=True,\n",
        "                  temperature=1.0):\n",
        "        batch_size = tf.shape(input_text)[0]\n",
        "        input_tokens = self.input_text_processor(input_text)\n",
        "        enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "        result_tokens = []\n",
        "        attention = []\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                                     enc_output=enc_output,\n",
        "                                     mask=(input_tokens != 0))\n",
        "\n",
        "            dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "            attention.append(dec_result.attention_weights)\n",
        "\n",
        "            new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "            # If a sequence produces an `end_token`, set it `done`\n",
        "            done = done | (new_tokens == self.end_token)\n",
        "            # Once a sequence is done it only produces 0-padding.\n",
        "            new_tokens = tf.where(done, tf.constant(\n",
        "                0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "            # Collect the generated tokens\n",
        "            result_tokens.append(new_tokens)\n",
        "\n",
        "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "                break\n",
        "\n",
        "        # Convert the list of generates token ids to a list of strings.\n",
        "        result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "        result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "        if return_attention:\n",
        "            attention_stack = tf.concat(attention, axis=1)\n",
        "            return {'text': result_text, 'attention': attention_stack}\n",
        "        else:\n",
        "            return {'text': result_text}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "    def __call__(self, input_text):\n",
        "        return self.translate(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate a translator\n",
        "translate = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "metadata": {
        "id": "BtJgUoquyZO_",
        "outputId": "4998fdca-942e-422b-9b23-acc5c8c36645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run it on a simple input:\n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    \"Dieu de nos pères.\",#Yɛn agyanom Nyankopɔn .'\n",
        "    #\"C'est ma vie.\",  # 'Eyi ne m’asetra .'\n",
        "])\n",
        "\n",
        "result = translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "#print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "metadata": {
        "id": "KxEOJS2sygHN",
        "outputId": "d7842e3b-afe1-4580-b294-2cdfc0f09619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a ɛma yɛn ani gye ho .\n",
            "\n",
            "CPU times: user 18.7 s, sys: 779 ms, total: 19.5 s\n",
            "Wall time: 20.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a function to plot attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_start_and_end_tokens(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "metadata": {
        "id": "R_kbJUQ91Gwm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify plot attention\n",
        "i=0\n",
        "plot_attention(result['attention'][i], input_text[i], result['text'][i])"
      ],
      "metadata": {
        "id": "a6rfUCLP2zXn",
        "outputId": "70dc34e3-9ed9-4d1b-be6c-ae21a9e8ab3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "svoGwXHY3EJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(translate, '/content/drive/MyDrive/fr_tw_seq2seq_translator',\n",
        "                    signatures={'serving_default': translate.__call__})"
      ],
      "metadata": {
        "id": "NHFcFkWJ3CcF",
        "outputId": "33374db5-a897-4cf1-9c0e-d34490812347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded = tf.saved_model.load('/content/drive/MyDrive/fr_tw_seq2seq_translator')\n",
        "result = reloaded(input_text)\n",
        "result['text'][0].numpy().decode('utf-8')"
      ],
      "metadata": {
        "id": "xpxhhNo09naB",
        "outputId": "42df78d8-de95-4ef1-d48a-ced92f02efbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a moyɛ mmarima no yɛ asiane .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU\n"
      ],
      "metadata": {
        "id": "UGP9mZqTvBzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "\n",
        "class Bleu():\n",
        "    def __init__(self, translator):\n",
        "        self.translator = translator\n",
        "\n",
        "    def get_bleuscore(self, testfile, referencefile, smothingfunction=None):\n",
        "        if type(testfile) == str and type(referencefile) == str:\n",
        "            # Open test file and read lines\n",
        "            f = open(testfile, \"r\")\n",
        "            hypothesis = f.readlines()\n",
        "            f.close()\n",
        "            # open refernce file and read lines\n",
        "            f = open(referencefile, \"r\")\n",
        "            reference = f.readlines()\n",
        "            f.close()\n",
        "        elif type(testfile) == list and type(referencefile) == list:\n",
        "            hypothesis = testfile\n",
        "            reference = referencefile\n",
        "        else:\n",
        "            print(f'File must be txt or python list')\n",
        "\n",
        "        # check the length of our input sentence\n",
        "        length = len(hypothesis)\n",
        "        bleu_total = np.array([0., 0., 0.])\n",
        "        weights = [(1./2, 1./2), (1./3, 1./3, 1./3),\n",
        "                   (1./4, 1./4, 1./4, 1./4)]\n",
        "        for i in range(length):\n",
        "            hypothesis[i] = hypothesis[i]\n",
        "            reference[i] = reference[i]\n",
        "            groundtruth = reference[i].lower().replace(\" ' \", \"'\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")\\\n",
        "                .replace(' \" ', '\" ').replace(' \"', '\"').replace(\" : \", \": \").replace(\" ( \", \" (\")\\\n",
        "                .replace(\" ) \", \") \").replace(\" , \", \", \").split(\" \")\n",
        "            groundtruth = [groundtruth]\n",
        "            input = tf.constant([hypothesis[1]])\n",
        "            result = self.translator(input)\n",
        "            translated_text = result['text'][0].numpy().decode(\"utf-8\")\n",
        "\n",
        "            #print(\"Translated Text: \", translated_text)\n",
        "            #print(\"Ground Truth: \", reference[i])\n",
        "            candidate = translated_text.replace(\" ' \", \"'\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")\\\n",
        "                .replace(' \" ', '\" ').replace(' \"', '\"').replace(\" : \", \": \").replace(\" ( \", \" (\")\\\n",
        "                .replace(\" ) \", \") \").replace(\" , \", \", \").split()\n",
        "            bleu = np.array(sentence_bleu(\n",
        "                groundtruth, candidate, weights, smoothing_function=smothingfunction))\n",
        "            bleu_total += bleu\n",
        "\n",
        "        return f'2-GRAMS: {bleu_total[0]/length}',f'3-GRAMS: {bleu_total[1]/length}',f'4-GRAMS: {bleu_total[2]/length}'"
      ],
      "metadata": {
        "id": "SguFKYfLvD10"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iNSTANTIATE OBJECT OF BLEU CLASS AND IT SMOOTHING FUNCTION\n",
        "smooth= SmoothingFunction()\n",
        "bleu = Bleu(reloaded)"
      ],
      "metadata": {
        "id": "cfjG3A_BvJvy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ESTIMATE BLEU SCORE FROM THE TEST DATA\n",
        "# from list\n",
        "bleu.get_bleuscore(french_test,twi_test,smooth.method2)"
      ],
      "metadata": {
        "id": "FlTY1ZYtvPRT",
        "outputId": "d4ed5514-ba69-4016-9599-724f3050a21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2-GRAMS: 0.037944437563595085',\n",
              " '3-GRAMS: 0.04011382527929214',\n",
              " '4-GRAMS: 0.04414486221144063')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogleAPI bleu"
      ],
      "metadata": {
        "id": "v8ChexIEvcq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use google API for bidirectional pivot translation of Twi and French\n",
        "# pivot language = English\n",
        "# import libraries\n",
        "from googletrans import Translator, constants\n",
        "# instantiate a translator object\n",
        "# initiate translator object\n",
        "translator = Translator()\n",
        "# Add Akan to the language supported by this package\n",
        "# Note the googletrans package has not  been updated to capture the new additions by google since May 2022\n",
        "# from https://translate.google.com/?sl=en&tl=ak&op=translate , the key and value for Twi is 'ak':'akan'\n",
        "constants.LANGUAGES['ak'] = 'akan'\n",
        "\n",
        "\n",
        "class GooglePivot:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def evaluate(self, sentences, src_key, dest_key):\n",
        "        eng_text = translator.translate(sentences, src=src_key, dest='en').text\n",
        "        print(eng_text)\n",
        "        output = translator.translate(eng_text, dest=dest_key).text\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class GoogleDirect:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def evaluate(self, sentences, src_key, dest_key):\n",
        "\n",
        "        return translator.translate(sentences, src=src_key, dest=dest_key).text"
      ],
      "metadata": {
        "id": "dsy_Y8eTvbto"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "\n",
        "class GoogleBleu():\n",
        "    def __init__(self, translator):\n",
        "        self.translator = translator\n",
        "\n",
        "    def get_bleuscore(self, testfile, referencefile,src_lang,dest_lang, smothingfunction=None):\n",
        "        if type(testfile) == str and type(referencefile) == str:\n",
        "            # Open test file and read lines\n",
        "            f = open(testfile, \"r\")\n",
        "            hypothesis = f.readlines()\n",
        "            f.close()\n",
        "            # open refernce file and read lines\n",
        "            f = open(referencefile, \"r\")\n",
        "            reference = f.readlines()\n",
        "            f.close()\n",
        "        elif type(testfile) == list and type(referencefile) == list:\n",
        "            hypothesis = testfile\n",
        "            reference = referencefile\n",
        "        else:\n",
        "            print(f'File must be txt or python list')\n",
        "\n",
        "        # check the length of our input sentence\n",
        "        length = len(hypothesis)\n",
        "        bleu_total = np.array([0., 0., 0.])\n",
        "        weights = [(1./2, 1./2), (1./3, 1./3, 1./3),\n",
        "                   (1./4, 1./4, 1./4, 1./4)]\n",
        "        for i in range(length):\n",
        "            hypothesis[i] = hypothesis[i]\n",
        "            reference[i] = reference[i]\n",
        "            groundtruth = reference[i].lower().replace(\" ' \", \"'\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")\\\n",
        "                .replace(' \" ', '\" ').replace(' \"', '\"').replace(\" : \", \": \").replace(\" ( \", \" (\")\\\n",
        "                .replace(\" ) \", \") \").replace(\" , \", \", \").split()\n",
        "            groundtruth = [groundtruth]\n",
        "            translated_text = self.translator.evaluate(hypothesis[i],src_key=src_lang, dest_key=dest_lang)\n",
        "            # print(\"Translated Text: \", translated_text)\n",
        "            # print(\"Ground Truth: \", reference[i])\n",
        "            candidate = translated_text.replace(\" ' \", \"'\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")\\\n",
        "                .replace(' \" ', '\" ').replace(' \"', '\"').replace(\" : \", \": \").replace(\" ( \", \" (\")\\\n",
        "                .replace(\" ) \", \") \").replace(\" , \", \", \").split()\n",
        "            bleu = np.array(sentence_bleu(\n",
        "                groundtruth, candidate, weights, smoothing_function=smothingfunction))\n",
        "            bleu_total += bleu\n",
        "\n",
        "        return f'2-GRAMS: {bleu_total[0]/length}',f'3-GRAMS: {bleu_total[1]/length}',f'4-GRAMS: {bleu_total[2]/length}'"
      ],
      "metadata": {
        "id": "IJ6yxd05vnyP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate GoogleDirect class\n",
        "google_translate = GoogleDirect()\n",
        "google_bleu = GoogleBleu(google_translate)"
      ],
      "metadata": {
        "id": "ywpKmrvKvsc3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "google_bleu.get_bleuscore(french_test,twi_test,'fr','ak',smooth.method2)"
      ],
      "metadata": {
        "id": "rofXQmYIv33v",
        "outputId": "05494163-d200-4138-b635-7010f905f98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.8 s, sys: 1.32 s, total: 15.2 s\n",
            "Wall time: 7min 5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2-GRAMS: 0.43171415910480654',\n",
              " '3-GRAMS: 0.3965439243128418',\n",
              " '4-GRAMS: 0.3734301840934506')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbQUEsuHIpyC"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}