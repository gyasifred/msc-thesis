{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/msc-thesis/blob/main/twi_french_seq2seq_nmt_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqAsWIXdaHh"
      },
      "source": [
        "This exercise will demonstrate how to build sequence to sequence models with attention for Twi-French machine translation. This code is based on the tensorflow implementation of the paper [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) (Luong et al., 2015).The code snippet are adapted from from [[1]](https://www.tensorflow.org/text/tutorials/nmt_with_attention)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-OJN6ybfEP"
      },
      "source": [
        "# Import Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPsStl-KdJmv",
        "outputId": "c0fe30a4-06ab-43b8-9798-8236b5310e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.48.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YET1BasJdKr9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k6W5V1Jg44R"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh5Z6XSTfREU"
      },
      "outputs": [],
      "source": [
        "# This code was adapted from https://github.com/GhanaNLP/kasa/blob/master/Kasa/Preprocessing.py\n",
        "# import required library\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "class Preprocessing:\n",
        "    # dummy initialization method\n",
        "    def __init__(self):\n",
        "        # initialize with some default parameters here later\n",
        "        pass\n",
        "\n",
        "    # read in parallel twi - french dataset\n",
        "    def read_parallel_dataset(self, filepath_twi, filepath_french):\n",
        "\n",
        "        # read french data\n",
        "        french_data = []\n",
        "        with open(filepath_french, encoding='utf-8') as file:\n",
        "            line = file.readline()\n",
        "            cnt = 1\n",
        "            while line:\n",
        "                french_data.append(line.strip())\n",
        "                line = file.readline()\n",
        "                cnt += 1\n",
        "\n",
        "        # read twi data\n",
        "        twi_data = []\n",
        "        with open(filepath_twi, encoding='utf-8') as file:\n",
        "\n",
        "            # twi=file.read()\n",
        "            line = file.readline()\n",
        "            cnt = 1\n",
        "            while line:\n",
        "                twi_data.append(line.strip())\n",
        "                line = file.readline()\n",
        "                cnt += 1\n",
        "\n",
        "        return twi_data, french_data\n",
        "\n",
        "    # Define a helper function to remove string accents\n",
        "\n",
        "    def removeStringAccent(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    # normalize input twi sentence\n",
        "    def normalize_twi(self, s):\n",
        "        s = self.removeStringAccent(s)\n",
        "        s = re.sub(r'([!.?])', r' \\1', s)\n",
        "        s = re.sub(r'[^a-zA-Z.ƆɔɛƐ!?’]+', r' ', s)\n",
        "        s = re.sub(r'\\s+', r' ', s)\n",
        "        return s\n",
        "\n",
        "    # normalize input french sentence\n",
        "    def normalize_fr(self, s):\n",
        "        s = self.removeStringAccent(s)\n",
        "        s = re.sub(r'([!.?])', r' \\1', s)\n",
        "        s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "        s = re.sub(r'\\s+', r' ', s)\n",
        "        return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL_-wwIOhEjY"
      },
      "outputs": [],
      "source": [
        "# Create an instance of tft preprocessing class\n",
        "\n",
        "TwiFrPreprocessor = Preprocessing()\n",
        "\n",
        "# Read raw parallel dataset\n",
        "raw_data_twi,raw_data_fr = TwiFrPreprocessor.read_parallel_dataset(\n",
        "        filepath_twi='/content/verified_twi.txt',\n",
        "        filepath_french='/content/verified_french.txt')\n",
        "\n",
        "# Normalize the raw data\n",
        "raw_data_fr = [TwiFrPreprocessor.normalize_fr(data) for data in raw_data_fr]\n",
        "raw_data_twi = [TwiFrPreprocessor.normalize_twi(data) for data in raw_data_twi]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TwuB3ClOJQy"
      },
      "outputs": [],
      "source": [
        "# define function to write text to txt file\n",
        "def writeTotxt(destination,data):\n",
        "  with open(destination, 'w') as f:\n",
        "    for line in data:\n",
        "        f.write(f\"{line}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmdIDyFYOOrH"
      },
      "outputs": [],
      "source": [
        "# write the preprocess french and twi lines to a file\n",
        "writeTotxt('twi_lines.txt',raw_data_twi)\n",
        "writeTotxt('fr_lines.txt',raw_data_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PJYVQVvNvJm"
      },
      "source": [
        "# Create a Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3UKlSzNPtwB"
      },
      "source": [
        "## Build tf Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lqHtHvCN27g"
      },
      "outputs": [],
      "source": [
        "full_dataset_fr = tf.data.TextLineDataset('/content/fr_lines.txt')\n",
        "full_dataset_tw = tf.data.TextLineDataset('/content/twi_lines.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvOh5UZ6RPeL"
      },
      "source": [
        "## Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgcUbiSASeqg"
      },
      "outputs": [],
      "source": [
        "# add start and end tokens\n",
        "def tf_start_and_end_tokens(text):\n",
        "    # Split accented characters.\n",
        "    #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    # Strip whitespace.\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n",
        "# set maximum vocaburary size\n",
        "max_vocab_size = 10000\n",
        "# Process twi as input\n",
        "twi_tokenizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_start_and_end_tokens,\n",
        "    max_tokens=max_vocab_size)\n",
        "twi_tokenizer.adapt(full_dataset_tw)\n",
        "\n",
        "# Process french as output\n",
        "french_tokenizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_start_and_end_tokens,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "french_tokenizer.adapt(full_dataset_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vQkzK52TG_d",
        "outputId": "f99b03a7-108c-4190-dbc8-8feb85394c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French Tokenizer: ['', '[UNK]', '[START]', '[END]', '.', 'a', 'de', 'je', 'est', 'il']\n",
            "French Tokenizer size: 9570\n",
            "\n",
            "TWI Tokenizer: ['abamu', 'abambu', 'abada', 'abaafo', 'aakwantuo', 'aa', '.r', '.meda', '.ma', '.abena']\n",
            "TWI Tokenizer size: 7750\n"
          ]
        }
      ],
      "source": [
        "# Print few lines of our tokenizers vocabulary and length\n",
        "print(f'French Tokenizer:',french_tokenizer.get_vocabulary()[:10])\n",
        "print(f'French Tokenizer size:',len(french_tokenizer.get_vocabulary()))\n",
        "\n",
        "print()\n",
        "print(f'TWI Tokenizer:',twi_tokenizer.get_vocabulary()[-10:])\n",
        "print(f'TWI Tokenizer size:',len(twi_tokenizer.get_vocabulary()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80o2o2FjZYD"
      },
      "source": [
        "# Create Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIAtMONkhNcF"
      },
      "outputs": [],
      "source": [
        "# split the dataset into training and test sets\n",
        "# Keep 20% of the data as test set\n",
        "train_twi,test_twi,train_fr,test_fr = train_test_split(raw_data_twi,raw_data_fr, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aFkzc8sj5vO"
      },
      "outputs": [],
      "source": [
        "# write the preprocess traning and test dataset to a file\n",
        "writeTotxt('train_twi.txt',train_twi)\n",
        "writeTotxt('train_fr.txt',train_fr)\n",
        "writeTotxt('test_twi.txt',test_twi)\n",
        "writeTotxt('test_fr.txt',test_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8H8yu3ykCy9"
      },
      "source": [
        "## Build tf Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqIWNiixj93A"
      },
      "outputs": [],
      "source": [
        "# build tf datasets from traning and test sentences in both languages\n",
        "train_dataset_fr = tf.data.TextLineDataset('/content/train_fr.txt')\n",
        "train_dataset_tw = tf.data.TextLineDataset('/content/train_twi.txt')\n",
        "\n",
        "val_dataset_fr = tf.data.TextLineDataset('/content/test_fr.txt')\n",
        "val_dataset_tw = tf.data.TextLineDataset('/content/test_twi.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnQ1hMH_kPm1"
      },
      "outputs": [],
      "source": [
        "# combine languages into single dataset\n",
        "trained_combined = tf.data.Dataset.zip((train_dataset_tw, train_dataset_fr))\n",
        "val_combined = tf.data.Dataset.zip((val_dataset_tw, val_dataset_fr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkpIb3EXkU_O",
        "outputId": "cd6b648d-1026-4dac-b372-b89806f47424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Twi:  Dɛn na mefi ase ?\n",
            "French:  Par quoi dois je commencer ?\n",
            "Twi:  Meresua sikasɛm ho ade wɔ suapɔn\n",
            "French:  J etudie l economie au college .\n",
            "Twi:  Saa asubɔnten yi mu nnɔ pii saa bere no .\n",
            "French:  Cette riviere devient peu profonde a cet endroit .\n",
            "Twi:  Asamoah ntumi nhu bere tenten a ɛsɛ sɛ ɔtwɛn Araba .\n",
            "French:  Asamoah se demanda combien de temps il devrait attendre Araba .\n",
            "Twi:  Dodow a me mfe rekɔ anim no dodow no ara na mekae nneɛma a amma saa da .\n",
            "French:  Plus je vieillis plus je me souviens clairement de choses qui ne se sont jamais produites .\n"
          ]
        }
      ],
      "source": [
        "# verify trained_combined dataset is correct\n",
        "for tw,fr in trained_combined.take(5):\n",
        "  print(\"Twi: \", tw.numpy().decode('utf-8'))\n",
        "  print(\"French: \", fr.numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr47kMLGlGan"
      },
      "source": [
        "## Create Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARuJ-j3dkaMV"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(train_twi) \n",
        "BATCH_SIZE = 64\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "  ds\n",
        "  .cache()\n",
        "  .shuffle(BUFFER_SIZE)\n",
        "  .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4E48b8fnR_Q"
      },
      "outputs": [],
      "source": [
        "# train batches\n",
        "trained_dataset = make_batches(trained_combined)\n",
        "# test batches\n",
        "val_dataset = make_batches(val_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnmDbsDDnW1G",
        "outputId": "bc1f2563-242c-4d31-ecd9-7cb932a6a046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'S\\xc9\\x9b obi a \\xc9\\x94w\\xc9\\x94 din pa no \\xc9\\x94ny\\xc9\\x9b odwontofo .'\n",
            " b'Na me w\\xc9\\x94fa ani gye adwinni ho yiye .'\n",
            " b'Mey\\xc9\\x9b\\xc9\\x9b nhyehy\\xc9\\x9be s\\xc9\\x9b m\\xc9\\x9btra kurow no mu .'\n",
            " b'Kwaku wer\\xc9\\x9b fii baabi a \\xc9\\x94de n ahwehw\\xc9\\x9b nniwa no toe'\n",
            " b'Mintumi nni \\xc9\\x94haw yi ho dwuma .'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'Asamoah n est pas un musicien professionnel .'\n",
            " b'Mon oncle a un profond interet pour l art .'\n",
            " b'Je compte rester en ville .'\n",
            " b'Kwaku a oublie ou il a mis ses lunettes .'\n",
            " b'Je ne peux pas resoudre ce probleme .'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# verify input and target\n",
        "for  example_input_batch,example_target_batch in trained_dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whFNrwDByRkO",
        "outputId": "8844baac-61de-4de2-8e64-d2e4b157817c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[   2,    6,   56,    7,  176,  144,   93,    5,  672, 2563],\n",
              "       [   2,    8,   11,  608,   24,   46, 1837,   13,   36,    4],\n",
              "       [   2,  409,  183,    6,  906,  243,    5,   14,    4,    3]])>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify tokenizer\n",
        "example_tokens = twi_tokenizer(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CoaRtkchybGn",
        "outputId": "4d3cf3a7-9ff3-421c-f97a-9401607d2eb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[START] sɛ obi a ɔwɔ din pa no ɔnyɛ odwontofo . [END]         '"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_vocab = np.array(twi_tokenizer.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTiUeXsy3bA"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "62XxlkwayyeI",
        "outputId": "3ae48c92-1ffb-4f97-d11d-59e52254a1bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOnz10TWzDeK"
      },
      "source": [
        "# Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLWhTwqK6Nhj"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                                   embedding_dim)\n",
        "\n",
        "        # The GRU RNN layer processes those vectors sequentially.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                         # Return the sequence and state\n",
        "                                         return_sequences=True,\n",
        "                                         return_state=True,\n",
        "                                         recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, tokens, state=None):\n",
        "        # The embedding layer looks up the embedding for each token.\n",
        "        vectors = self.embedding(tokens)\n",
        "\n",
        "        # The GRU processes the embedding sequence.\n",
        "        #    output shape: (batch, s, enc_units)\n",
        "        #    state shape: (batch, enc_units)\n",
        "        output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "        # 4. Returns the new sequence and its state.\n",
        "        return output, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AcFzlXhDjBn"
      },
      "source": [
        "# Create Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G55yaW0U-w_X"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "        self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "    def call(self, query, value, mask):\n",
        "        w1_query = self.W1(query)\n",
        "        w2_key = self.W2(value)\n",
        "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "        value_mask = mask\n",
        "\n",
        "        context_vector, attention_weights = self.attention(\n",
        "            inputs=[w1_query, value, w2_key],\n",
        "            mask=[query_mask, value_mask],\n",
        "            return_attention_scores=True,\n",
        "        )\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afqcLYScH3ab"
      },
      "source": [
        "# Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTQH_4OsEgAa"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # For Step 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                                   embedding_dim)\n",
        "\n",
        "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "        self.gru= tf.keras.layers.GRU(self.dec_units,\n",
        "                                         return_sequences=True,\n",
        "                                         return_state=True,\n",
        "                                         recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # For step 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                        use_bias=False)\n",
        "\n",
        "        # For step 5. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
        "\n",
        "\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "    new_tokens: Any\n",
        "    enc_output: Any\n",
        "    mask: Any\n",
        "\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "    logits: Any\n",
        "    attention_weights: Any\n",
        "\n",
        "\n",
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "\n",
        "    # Step 1. Lookup the embeddings\n",
        "    vectors = self.embedding(inputs.new_tokens)\n",
        "    # Step 2. Process one step with the RNN\n",
        "    rnn_output,state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "    # Step 3. Use the RNN output as the query for the attention over the\n",
        "    # encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "    # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "    #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "    # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "    attention_vector = self.Wc(context_and_rnn_output)\n",
        "    # Step 5. Generate logit predictions:\n",
        "    logits = self.fc(attention_vector)\n",
        "    return DecoderOutput(logits, attention_weights), state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN705AnxIDb6"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl0R2Zg6SkRI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgyqEVm2Ku8T"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        self.name = 'masked_loss'\n",
        "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction='none')\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "\n",
        "        # Calculate the loss for each item in the batch.\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "\n",
        "        # Mask off the losses on padding.\n",
        "        mask = tf.cast(y_true != 0, tf.float32)\n",
        "        loss *= mask\n",
        "\n",
        "        # Return the total.\n",
        "        return tf.reduce_sum(loss)\n",
        "\n",
        "\n",
        "class TrainTranslator(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, units,\n",
        "                 input_text_processor,\n",
        "                 output_text_processor,\n",
        "                 use_tf_function=True):\n",
        "        super().__init__()\n",
        "        # Build the encoder and decoder\n",
        "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                          embedding_dim, units)\n",
        "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                          embedding_dim, units)\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.input_text_processor = input_text_processor\n",
        "        self.output_text_processor = output_text_processor\n",
        "        self.use_tf_function = use_tf_function\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        # .shape_checker = ShapeChecker()\n",
        "        if self.use_tf_function:\n",
        "            return self._tf_train_step(inputs)\n",
        "        else:\n",
        "            return self._train_step(inputs)\n",
        "\n",
        "    # Implement preprocessing step to:\n",
        "    # Receive a batch of input_text, target_text from the tf.data.Dataset.\n",
        "    # Convert those raw text inputs to token-embeddings and masks.\n",
        "    def _preprocess(self, input_text, target_text):\n",
        "        # Convert the text to token IDs\n",
        "        input_tokens = self.input_text_processor(input_text)\n",
        "        target_tokens = self.output_text_processor(target_text)\n",
        "        # Convert IDs to masks.\n",
        "        input_mask = input_tokens != 0\n",
        "\n",
        "        target_mask = target_tokens != 0\n",
        "        return input_tokens, input_mask, target_tokens, target_mask\n",
        "\n",
        "    # the function The _train_step:\n",
        "    # Run the encoder on the input_tokens to get the encoder_output and encoder_state.\n",
        "    # Initialize the decoder state and loss.\n",
        "    # Loop over the target_tokens:\n",
        "    #   Run the decoder one step at a time.\n",
        "    #   Calculate the loss for each step.\n",
        "    # Accumulate the average loss.\n",
        "    # Calculate the gradient of the loss and use the optimizer to apply updates to the model's trainable_variables.\n",
        "\n",
        "    def _train_step(self, inputs):\n",
        "        input_text, target_text = inputs\n",
        "\n",
        "        (input_tokens, input_mask,\n",
        "         target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "        max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Encode the input\n",
        "            enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "            # Initialize the decoder's state to the encoder's final state.\n",
        "            # This only works if the encoder and decoder have the same number of\n",
        "            # units.\n",
        "            dec_state = enc_state\n",
        "            loss = tf.constant(0.0)\n",
        "\n",
        "            for t in tf.range(max_target_length-1):\n",
        "                # Pass in two tokens from the target sequence:\n",
        "                # 1. The current input to the decoder.\n",
        "                # 2. The target for the decoder's next prediction.\n",
        "                new_tokens = target_tokens[:, t:t+2]\n",
        "                step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                                       enc_output, dec_state)\n",
        "                loss = loss + step_loss\n",
        "\n",
        "            # Average the loss over all non padding tokens.\n",
        "            average_loss = loss / \\\n",
        "                tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "        # Apply an optimization step\n",
        "        variables = self.trainable_variables\n",
        "        gradients = tape.gradient(average_loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {'batch_loss': average_loss}\n",
        "\n",
        "    # The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state).\n",
        "\n",
        "    def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "        input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "        # Run the decoder one step.\n",
        "        decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                                     enc_output=enc_output,\n",
        "                                     mask=input_mask)\n",
        "\n",
        "        dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "        # `self.loss` returns the total for non-padded tokens\n",
        "        y = target_token\n",
        "        y_pred = dec_result.logits\n",
        "        step_loss = self.loss(y, y_pred)\n",
        "\n",
        "        return step_loss, dec_state\n",
        "\n",
        "    @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "    def _tf_train_step(self, inputs):\n",
        "        return self._train_step(inputs)\n",
        "\n",
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI0V2_YNSpO2"
      },
      "outputs": [],
      "source": [
        "# SET INPUT AND OUTPUT PROCESSOR\n",
        "input_text_processor = twi_tokenizer\n",
        "output_text_processor = french_tokenizer\n",
        "\n",
        "# set Hyerperameters\n",
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31yGNhKaaSU8"
      },
      "outputs": [],
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")\n",
        "train_translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRCC98HFb7zG",
        "outputId": "5687eace-5a90-4fd9-8e93-72522190c260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "318/318 [==============================] - 109s 315ms/step - batch_loss: 4.6108\n",
            "Epoch 2/50\n",
            "318/318 [==============================] - 101s 316ms/step - batch_loss: 3.4342\n",
            "Epoch 3/50\n",
            "318/318 [==============================] - 100s 313ms/step - batch_loss: 2.7309\n",
            "Epoch 4/50\n",
            "318/318 [==============================] - 98s 307ms/step - batch_loss: 2.1572\n",
            "Epoch 5/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 1.6228\n",
            "Epoch 6/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 1.1613\n",
            "Epoch 7/50\n",
            "318/318 [==============================] - 96s 301ms/step - batch_loss: 0.7941\n",
            "Epoch 8/50\n",
            "318/318 [==============================] - 98s 307ms/step - batch_loss: 0.5165\n",
            "Epoch 9/50\n",
            "318/318 [==============================] - 99s 311ms/step - batch_loss: 0.3207\n",
            "Epoch 10/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.1911\n",
            "Epoch 11/50\n",
            "318/318 [==============================] - 98s 309ms/step - batch_loss: 0.1115\n",
            "Epoch 12/50\n",
            "318/318 [==============================] - 98s 309ms/step - batch_loss: 0.0665\n",
            "Epoch 13/50\n",
            "318/318 [==============================] - 98s 309ms/step - batch_loss: 0.0440\n",
            "Epoch 14/50\n",
            "318/318 [==============================] - 98s 309ms/step - batch_loss: 0.0357\n",
            "Epoch 15/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.0367\n",
            "Epoch 16/50\n",
            "318/318 [==============================] - 98s 309ms/step - batch_loss: 0.0975\n",
            "Epoch 17/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 0.2945\n",
            "Epoch 18/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 0.1623\n",
            "Epoch 19/50\n",
            "318/318 [==============================] - 98s 308ms/step - batch_loss: 0.0609\n",
            "Epoch 20/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.0282\n",
            "Epoch 21/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0181\n",
            "Epoch 22/50\n",
            "318/318 [==============================] - 97s 303ms/step - batch_loss: 0.0149\n",
            "Epoch 23/50\n",
            "318/318 [==============================] - 98s 308ms/step - batch_loss: 0.0140\n",
            "Epoch 24/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 0.0148\n",
            "Epoch 25/50\n",
            "318/318 [==============================] - 96s 301ms/step - batch_loss: 0.0189\n",
            "Epoch 26/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 0.0938\n",
            "Epoch 27/50\n",
            "318/318 [==============================] - 97s 306ms/step - batch_loss: 0.3986\n",
            "Epoch 28/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.1422\n",
            "Epoch 29/50\n",
            "318/318 [==============================] - 98s 308ms/step - batch_loss: 0.0474\n",
            "Epoch 30/50\n",
            "318/318 [==============================] - 102s 320ms/step - batch_loss: 0.0219\n",
            "Epoch 31/50\n",
            "318/318 [==============================] - 99s 310ms/step - batch_loss: 0.0144\n",
            "Epoch 32/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.0131\n",
            "Epoch 33/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0124\n",
            "Epoch 34/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0123\n",
            "Epoch 35/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.0131\n",
            "Epoch 36/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0154\n",
            "Epoch 37/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 0.0999\n",
            "Epoch 38/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 0.3914\n",
            "Epoch 39/50\n",
            "318/318 [==============================] - 95s 300ms/step - batch_loss: 0.1409\n",
            "Epoch 40/50\n",
            "318/318 [==============================] - 96s 301ms/step - batch_loss: 0.0464\n",
            "Epoch 41/50\n",
            "318/318 [==============================] - 96s 303ms/step - batch_loss: 0.0216\n",
            "Epoch 42/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0136\n",
            "Epoch 43/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 0.0123\n",
            "Epoch 44/50\n",
            "318/318 [==============================] - 96s 302ms/step - batch_loss: 0.0113\n",
            "Epoch 45/50\n",
            "318/318 [==============================] - 98s 307ms/step - batch_loss: 0.0111\n",
            "Epoch 46/50\n",
            "318/318 [==============================] - 99s 312ms/step - batch_loss: 0.0117\n",
            "Epoch 47/50\n",
            "318/318 [==============================] - 97s 305ms/step - batch_loss: 0.0139\n",
            "Epoch 48/50\n",
            "318/318 [==============================] - 97s 306ms/step - batch_loss: 0.0195\n",
            "Epoch 49/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 0.2749\n",
            "Epoch 50/50\n",
            "318/318 [==============================] - 97s 304ms/step - batch_loss: 0.2811\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda0003f410>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_translator.fit(trained_dataset, epochs=20,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ej3vGAWRb9Pt",
        "outputId": "3af38bad-e93b-452e-8349-381c770fa1e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXqJ52MDyMNt"
      },
      "source": [
        "# Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p4NpHontQwGV"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, input_text_processor,\n",
        "                 output_text_processor):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.input_text_processor = input_text_processor\n",
        "        self.output_text_processor = output_text_processor\n",
        "\n",
        "        self.output_token_string_from_index = (\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=output_text_processor.get_vocabulary(),\n",
        "                mask_token='',\n",
        "                invert=True))\n",
        "\n",
        "        # The output should never generate padding, unknown, or start.\n",
        "        index_from_string = tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "        token_mask = np.zeros(\n",
        "            [index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "        token_mask[np.array(token_mask_ids)] = True\n",
        "        self.token_mask = token_mask\n",
        "\n",
        "        self.start_token = index_from_string(tf.constant('[START]'))\n",
        "        self.end_token = index_from_string(tf.constant('[END]'))\n",
        "\n",
        "    def tokens_to_text(self, result_tokens):\n",
        "        result_text_tokens = self.output_token_string_from_index(\n",
        "            result_tokens)\n",
        "        result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                             axis=1, separator=' ')\n",
        "        result_text = tf.strings.strip(result_text)\n",
        "        return result_text\n",
        "\n",
        "    def sample(self, logits, temperature):\n",
        "        token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "        logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "        if temperature == 0.0:\n",
        "            new_tokens = tf.argmax(logits, axis=-1)\n",
        "        else:\n",
        "            logits = tf.squeeze(logits, axis=1)\n",
        "            new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                               num_samples=1)\n",
        "\n",
        "        return new_tokens\n",
        "\n",
        "    def translate(self,\n",
        "                  input_text, *,\n",
        "                  max_length=50,\n",
        "                  return_attention=True,\n",
        "                  temperature=1.0):\n",
        "        batch_size = tf.shape(input_text)[0]\n",
        "        input_tokens = self.input_text_processor(input_text)\n",
        "        enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "        result_tokens = []\n",
        "        attention = []\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                                     enc_output=enc_output,\n",
        "                                     mask=(input_tokens != 0))\n",
        "\n",
        "            dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "            attention.append(dec_result.attention_weights)\n",
        "\n",
        "            new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "            # If a sequence produces an `end_token`, set it `done`\n",
        "            done = done | (new_tokens == self.end_token)\n",
        "            # Once a sequence is done it only produces 0-padding.\n",
        "            new_tokens = tf.where(done, tf.constant(\n",
        "                0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "            # Collect the generated tokens\n",
        "            result_tokens.append(new_tokens)\n",
        "\n",
        "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "                break\n",
        "\n",
        "        # Convert the list of generates token ids to a list of strings.\n",
        "        result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "        result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "        if return_attention:\n",
        "            attention_stack = tf.concat(attention, axis=1)\n",
        "            return {'text': result_text, 'attention': attention_stack}\n",
        "        else:\n",
        "            return {'text': result_text}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "    def __call__(self, input_text):\n",
        "        return self.translate(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BtJgUoquyZO_",
        "outputId": "9770b8f0-b7e9-48fb-bef1-09c80ee73b99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "# instantiate a translator\n",
        "translate = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KxEOJS2sygHN",
        "outputId": "588c5f2e-1dd1-4b43-dfb1-713e67e54482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nous sommes de notre ressources .\n",
            "c est la norme .\n",
            "\n",
            "CPU times: user 19.1 s, sys: 643 ms, total: 19.7 s\n",
            "Wall time: 21.1 s\n"
          ]
        }
      ],
      "source": [
        "# Run it on a simple input:\n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'Yɛn agyanom Nyankopɔn .', # \"Dieu de nos pères.\"\n",
        "    'Eyi ne m’asetra .', # \"C'est ma vie.\"\"\n",
        "])\n",
        "\n",
        "result = translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R_kbJUQ91Gwm"
      },
      "outputs": [],
      "source": [
        "# set up a function to plot attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_start_and_end_tokens(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a6rfUCLP2zXn",
        "outputId": "4c299806-5938-4d9d-ee98-cae913e08b57"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# verify plot attention\n",
        "i=0\n",
        "plot_attention(result['attention'][i], input_text[i], result['text'][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svoGwXHY3EJL"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NHFcFkWJ3CcF",
        "outputId": "8a5f8e7f-f441-4873-b918-e9b776ea2482"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(translate, '/content/drive/MyDrive/tw_fr_seq2seq_translator',\n",
        "                    signatures={'serving_default': translate.__call__})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpxhhNo09naB"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('/content/drive/MyDrive/tw_fr_seq2seq_translator')\n",
        "result = reloaded(input_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}